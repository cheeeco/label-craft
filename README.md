# Label Craft

Система автоматической категоризации товаров по их названию и атрибутам с использованием предобученных языковых моделей и иерархических метрик качества.

## Постановка задачи

Проект разработан в рамках соревнования по автоматической категоризации товаров. Основная задача — разработать алгоритм для классификации товаров по их названию и атрибутам в условиях неполной и неидеальной разметки.

### Вызовы задачи

- **Иерархическая структура**: Система категорий организована в виде дерева с до 5 уровней вложенности
- **Множественные источники**: Данные поступают с различных торговых площадок с разными форматами атрибутов
- **Неполная разметка**: Атрибуты товаров могут отличаться между площадками или отсутствовать
- **Динамическое развитие**: Появление новых площадок и категорий по мере расширения каталога

## Описание проекта

Label Craft — это MLOps-решение для решения задачи категоризации товаров, построенное на базе PyTorch Lightning и предобученной модели ruBERT-tiny2. Проект реализует полный цикл машинного обучения: от загрузки и предобработки данных до обучения модели и инференса с использованием современных практик MLOps.

### Ключевые особенности

- **Предобученная модель**: Использование ruBERT-tiny2 для русскоязычных текстов
- **Иерархические метрики**: Специальная метрика HDA (Hierarchical Distance Accuracy) для оценки качества классификации
- **MLOps-инфраструктура**: Интеграция с MLflow для трекинга экспериментов, DVC для версионирования данных
- **Конфигурируемость**: Гибкая настройка через Hydra конфигурации
- **Масштабируемость**: Поддержка GPU/CPU, батчевая обработка

### Архитектура

Проект построен по модульному принципу:
- `data/` — модуль для работы с данными и предобработки
- `models/` — архитектура модели и логика обучения
- `metrics/` — кастомные метрики качества
- `logging/` — интеграция с MLflow
- `scripts/` — утилиты для загрузки данных

## Setup

### Требования

- Python 3.9+
- Poetry (для управления зависимостями)
- CUDA (опционально, для GPU)

### Установка

1. **Клонирование репозитория**:
```bash
git clone <repository-url>
cd label-craft
```

2. **Установка зависимостей**:
```bash
poetry install
```

3. **Настройка pre-commit** (опционально):
```bash
poetry run pre-commit install
```

4. **Загрузка данных**:

   **Способ 1 - Прямой вызов скрипта**:
   ```bash
   poetry run python label_craft/scripts/download_data.py
   ```

   **Способ 2 - Через DVC**:
   ```bash
   poetry shell
   dvc repro
   ```

### Структура данных

После загрузки в директории `data/` должны появиться файлы:
- `labeled_train.parquet` — обучающие данные товаров с метками категорий
- `labeled_test.parquet` — тестовые данные товаров с метками категорий  
- `unlabeled_train.parquet` — неразмеченные данные товаров
- `category_tree.csv` — иерархическое дерево категорий (до 5 уровней)

Каждый табличный файл содержит колонки:
- `hash_id` — уникальный идентификатор товара
- `source_name` — название товара
- `attributes` — атрибуты товара (характеристики, описание)
- `cat_id` — идентификатор категории (только для размеченных данных)

## Train

### Обучение модели

Запуск обучения с конфигурацией по умолчанию:

```bash
poetry run train
```

### Конфигурация обучения

Основные параметры настраиваются в `config/train.yaml`:

- `training.max_epochs` — количество эпох (по умолчанию: 10)
- `training.precision` — точность вычислений (16 для GPU, 32 для CPU)
- `data.batch_size` — размер батча (по умолчанию: 64)
- `data.training_size` — доля данных для обучения (по умолчанию: 0.1)

### Мониторинг обучения

- **TensorBoard**: Логи сохраняются в `logs/text_classifier/`
- **MLflow**: Эксперименты трекаются в `mlruns/`
- **Checkpoints**: Модели сохраняются в `logs/text_classifier/version_X/checkpoints/`

### Пример запуска с кастомными параметрами

```bash
poetry run train training.max_epochs=20 data.batch_size=32
```

## Production preparation

### Подготовка модели к продакшену

1. **Проверка checkpoint'а**:
```bash
# Убедитесь, что checkpoint существует
ls logs/text_classifier/version_X/checkpoints/
```

2. **Обновление конфигурации инференса**:
Отредактируйте `config/inference.yaml`:
```yaml
model_checkpoint: "logs/text_classifier/version_X/checkpoints/best-model-XX-XX.XX.ckpt"
```

3. **Комплектация поставки**:
Для продакшена необходимы:
- Обученная модель (`.ckpt` файл)
- Конфигурационные файлы (`config/`)
- Скрипт инференса (`label_craft/inference.py`)
- Зависимости (`pyproject.toml`)

### Минимальные зависимости для инференса

Для продакшена достаточно:
- PyTorch
- Transformers
- Pandas
- PyArrow
- Scikit-learn

## Infer

### Запуск инференса

```bash
poetry run inference
```

### Формат входных данных

Модель ожидает данные о товарах в формате Parquet со следующими колонками:
- `source_name` — название товара
- `attributes` — атрибуты товара (характеристики, описание) для классификации
- `cat_id` — метки категорий (опционально, для оценки качества)
- `hash_id` — уникальный идентификатор товара (опционально)


### Результаты инференса

Скрипт создает файл `predictions.csv` с колонками:
- `predicted_label` — предсказанный класс
- `prediction_confidence` — уверенность модели
- `top_1_prediction`, `top_2_prediction`, `top_3_prediction` — топ-3 предсказания
- `top_1_confidence`, `top_2_confidence`, `top_3_confidence` — уверенности для топ-3

### Оценка качества

Если в данных есть метки (`cat_id`), автоматически вычисляются:
- Accuracy
- F1-score (macro)
- HDA (Hierarchical Distance Accuracy)
- Exact match rate
- Partial match rate

### Конфигурация инференса

Основные параметры в `config/inference.yaml`:
- `test_data_path` — путь к тестовым данным
- `model_checkpoint` — путь к обученной модели
- `inference.batch_size` — размер батча для инференса
- `inference.device` — устройство (auto/cpu/cuda)